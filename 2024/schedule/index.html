<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Program | Graph Signal Processing Workshop</title> <meta name="author" content="Graph Signal Processing Workshop 2025 "/> <meta name="description" content="GSP Workshop 2025. "/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="preconnect" href="https://fonts.googleapis.com"> <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin> <link href="https://fonts.googleapis.com/css2?family=Noto+Sans:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap" rel="stylesheet"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚛️</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://gspworkshop2025.github.io/2024/schedule/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script>$(document).ready(function(){if(window.location.hash){var o=window.location.hash;history.replaceState(null,null,window.location.pathname+window.location.search),window.location.href=window.location.href+o,console.warn("Warning")}});</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title" href="/">Home</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/"></a> </li> <li class="nav-item active"> <a class="nav-link" href="/schedule/">Program<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/venue/">Venue</a> </li> <li class="nav-item "> <a class="nav-link" href="/registration/">Registration</a> </li> <li class="nav-item "> <a class="nav-link" href="/call_for_papers/">Call for papers</a> </li> <li class="nav-item "> <a class="nav-link" href="/submit/">Submit</a> </li> <li class="nav-item "> <a class="nav-link" href="/patrons/">Patrons</a> </li> <li class="nav-item "> <a class="nav-link" href="/previous/">Previous editions</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <article> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/gsp24/university-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/gsp24/university-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/gsp24/university-1400.webp"></source> <img src="/assets/img/gsp24/university.jpg" class="img-fluid z-depth-1 rounded" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure><br> <p><strong>Access a .pdf version of the technical program and the program-at-a-glance <a href="https://www.dropbox.com/scl/fi/f2rark72ev8afqk6k0gdi/GSP2024-Technical-Program.pdf?rlkey=7seagf3hnd6sf5vuabij65vcg&amp;dl=0" target="_blank" rel="noopener noreferrer">here</a>.</strong></p> <hr> <h4 id="program-at-a-glance">Program-At-A-Glance</h4> <div class="row justify-content-sm-center"> <div class="col-sm-12 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/gsp24/at-a-glance-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/gsp24/at-a-glance-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/gsp24/at-a-glance-1400.webp"></source> <img src="/assets/img/gsp24/at-a-glance.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" alt="Responsive image" title="Program at a glance" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <hr> <h4 id="general-information">General Information</h4> <p>Lectures in the oral sessions are 20-minutes long (including Q&amp;As). The format of posters is flexible, but A0 size and portrait orientation are recommended.</p> <p>There will be a single poster session per day. The session takes place during two different time slots (13h00 to 14h00 and 15h00 to 16h00) but the posters will be the same.</p> <p>There will be two social events:</p> <ul> <li>Welcome Reception: Monday 24 June, 19:00-21:30 <a href="https://www.google.com/maps/place/Loetje+Delft/@52.0066161,4.3552135,16z/data=!4m6!3m5!1s0x47c5b5124d2fb7c1:0x2498d3d454471ddc!8m2!3d52.0066161!4d4.3603633!16s%2Fg%2F11lryfs42l?entry=ttu" target="_blank" rel="noopener noreferrer">@Loetje Delft</a> </li> <li>Conference Banquet: Tuesday 25 June, 18:00-23:00 <a href="https://www.google.com/maps/place/Heinde+Delft/@52.0159234,4.3455105,17z/data=!3m1!4b1!4m6!3m5!1s0x47c5b5ad43f42cd5:0x36a8a0a343e4bde3!8m2!3d52.0159234!4d4.3455105!16s%2Fg%2F11fhy2swcv?entry=ttu" target="_blank" rel="noopener noreferrer">@Heinde Delft</a> </li> </ul> <hr> <h4 id="plenary-talks">Plenary Talks</h4> <p id="Georgios B. Giannakis"></p> <h5 id="plenary-monday-900---1000">Plenary Monday 9:00 - 10:00</h5> <p><a href="https://spincom.umn.edu/" target="_blank" rel="noopener noreferrer"><strong>Georgios B. Giannakis</strong></a>, University of Minnesota</p> <p><strong>Title</strong>: Kernel-driven and Learnable Self-Supervision over Graphs</p> <p><strong>Abstract</strong>: Self-supervision (SeSu) has gained popularity for data-hungry training of machine learning models, especially those involving large-scale graphs, where labeled samples are scarce or even unavailable. Main learning tasks in such setups are ill posed, and SeSu renders them well posed by relying on abundant unlabeled data as input, to yield low-dimensional embeddings of a reference (auxiliary) model output. In this talk, we first outline SeSu approaches, specialized reference models, and their links with (variational) auto-encoders, regularization, semi-supervised, transfer, meta, and multi-view learning; but also their challenges and opportunities when multi-layer graph topologies and multi-view data are present, when nodal features are absent, and when the ad hoc selection of a reference model yields embeddings not optimally designed for the downstream main learning task. Next, we present our novel SeSu approach which selects the reference model to output either a prescribed kernel, or, a learnable weighted superposition of kernels from a prescribed dictionary. As a result, the learned embeddings offer a novel, reduced-dimensionality estimate of the basis kernel, and thus an efficient parametric estimate of the main learning function at hand that belongs to a reproducing kernel Hilbert space. If time allows, we will also cover online variants for dynamic settings, and regret analysis founded on the so-termed neural-tangent-kernel framework to assess how effectively the learned embeddings approximate the underlying optimal kernel(s). We will wrap up with numerical tests using synthetic and real datasets to showcase the merits of kernel-driven and learnable (KeLe) SeSu relative to alternatives. The real data will also compare KeLe-SeSu with auto-encoders and graph neural networks (GNNs), and further test KeLe-Su on reference maps with masked-inputs and predicted-outputs that are popular in large language models (LLMs).</p> <p id="Francesca Parise"></p> <h5 id="plenary-monday-1400---1500">Plenary Monday 14:00 - 15:00</h5> <p><a href="https://sites.coecis.cornell.edu/parise/" target="_blank" rel="noopener noreferrer"><strong>Francesca Parise</strong></a>, Cornell University</p> <p><strong>Title</strong>: Large-Scale Network Dynamics: Achieving Tractability via Graph Limits</p> <p><strong>Abstract</strong>: Network dynamical systems provide a versatile framework for studying the interplay between the structure of complex networks and the dynamic behavior of its constituent entities, offering insights into diverse phenomena across disciplines such as physics, biology, sociology, and engineering. As the size of the underlying network increases however a number of new challenges arise. For example, collecting exact network data may become too costly and planning optimal network interventions may become computationally intractable. In this talk I will show how the theory of graph limits can be used to provide new insights on graph processes evolving over large random networks. First, I will show how graph limits can be used to define tractable infinite population models of network systems while maintaining agents heterogeneity. Second, I will show how insights derived for such infinite population models can be applied to study large but finite networks. I will illustrate the benefit of this graph limit approach for broad classes of graph processes including strategic interactions, multi-agent learning and synchronization dynamics.</p> <p id="Smita Krishnaswamy"></p> <h5 id="plenary-tuesday-900---1000">Plenary Tuesday 9:00 - 10:00</h5> <p><a href="https://krishnaswamylab.org/" target="_blank" rel="noopener noreferrer"><strong>Smita Krishnaswamy</strong></a>, Yale University</p> <p><strong>Title</strong>: Molecular discovery and analysis using geometric scattering and deep learning</p> <p><strong>Abstract</strong>: Here we present frameworks that integrate graph signal processing with deep learning in order to enhance graph representation-learning as well as predictive modeling of graph dynamics. A key innovation is our development and incorporation of learnable geometric scattering as well as its novel extensions bilipschitz scattering, directed scattering and scattering with attention, as layers into deep neural networks in order to improve expressiveness and downstream performance. We first discuss enhanced expressiveness and capability of capturing geometric properties of these methods. Then, we show applications in molecule generation, dynamics interpolation, as well as property prediction in small molecules and proteins. Finally, I will show applications where the structure captured by the graph signal processing is augmented by sequence analysis to elucidate basic RNA transcriptional biology.</p> <p id="Stefan Vlaski"></p> <h5 id="plenary-tuesday-1400---1500">Plenary Tuesday 14:00 - 15:00</h5> <p><a href="https://stefanvlaski.github.io/" target="_blank" rel="noopener noreferrer"><strong>Stefan Vlaski</strong></a>, Imperial College London</p> <p><strong>Title</strong>: Beyond Consensus-Based Methods for Decentralized Learning: Where Graph Signal Processing and Optimization Meet</p> <p><strong>Abstract</strong>: Recent years have been marked by a proliferation of dispersed data and computational capabilities. Data is generated and processed on our mobile devices, in sensors scattered throughout smart cities and smart grids , and vehicles on the road. Central aggregation of raw data is frequently neither efficient nor feasible, due to concerns around communication constraints, privacy, and robustness to link and node failure. The purpose of decentralized optimization and learning is then to devise intelligent systems by means of decentralized processing and peer-to-peer interactions, as defined by an underlying graph topology. Classically, the objective in decentralized learning has been to match the dynamics and performance of a centralized fusion center, and minimize the impact of the network on the learning dynamics. In convex, cooperative, and homogeneous environments, this paradigm is indeed optimal and can be shown to match statistical and information theoretic lower bounds. Modern learning applications, however, differ substantially from classical settings: They are highly non-convex, underdetermined, heterogeneous, and subject to non-cooperative and adversarial behavior. We will argue that effective learning in these environments requires deviation from the traditional consensus-based learning paradigm, and a refined characterization of the inductive bias and learning dynamics induced by the underlying graph topology. We will survey recent results emerging from this point of view.</p> <p id="Piet Van Mieghem"></p> <h5 id="plenary-wednesday-900---1000">Plenary Wednesday 9:00 - 10:00</h5> <p><a href="https://www.nas.ewi.tudelft.nl/people/Piet/" target="_blank" rel="noopener noreferrer"><strong>Piet Van Mieghem</strong></a>, TU Delft</p> <p><strong>Title</strong>: Linear Processes on Networks</p> <p><strong>Abstract</strong>: From a network science point of view, we will discuss linear processes on a graph, which are the easiest, but also the most elegant processes. Real, time-dependent processes necessitate us to introduce the beautiful linear state space (LSS) model (in discrete time). We will briefly talk about two applications of LSS. Thereafter, we switch to the Laplacian matrix of a graph. From the spectral decomposition of the Laplacian, we will introduce the simplex of an undirected, possibly weighted graph. The simplex geometry of a graph is, besides the topology domain and the spectral domain, the third equivalent description of a graph. Continuous-time Markov processes are described by the Chapman-Kolmogorov (linear) equations, in which the appearing infinitesimal generator is, in fact, a weighted Laplacian of the Markov graph. We will discuss Markovian epidemics on a fixed graph, show limitations of the linear theory on graphs and introduce a mean-field approximation, a powerful method from physics, that results into non-linear governing equations.</p> <p id="Sergio Barbarossa"></p> <h5 id="plenary-wednesday-1400---1500">Plenary Wednesday 14:00 - 15:00</h5> <p><a href="https://sites.google.com/a/uniroma1.it/sergiobarbarossa/home" target="_blank" rel="noopener noreferrer"><strong>Sergio Barbarossa</strong></a>, Sapienza University of Rome</p> <p><strong>Title</strong>: Topological signal processing and learning over cell complexes</p> <p><strong>Abstract</strong>: The goal of this lecture is to introduce the basic tools for processing signals defined over a topological space, focusing on simplicial and cell complexes. Nowadays, processing signals defined over graphs has become a mature technology. Graphs are just an example of topological space, incorporating only pairwise relations. In this lecture, we will motivate the need to generalize the graph-based methodologies to higher order structures, such as simplicial and cell complexes as spaces able to incorporate higher order relations in the representation space, still possessing a rich algebraic structure that facilitates the extraction of information. We will motivate the introduction of a Fourier Transform and recall the fundamentals of filtering and sampling of signals defined over such spaces. We will then show the impact of imperfect knowledge of the space on the tools used to extract information from data. Then we will present a probabilistic topological model for multivariate random variables defined over subsets of the space. Finally, we will show how to exploit the above tools in the design of topological neural networks, operating over signals defined over topological spaces of different order and we will present methods to infer the structure of the space from data.</p> <hr> <h4 id="oral-sessions">Oral Sessions</h4> <h4 id="oral-session-mon-am-monday-1030---1230---network-topology-inference">Oral Session Mon-AM (Monday 10:30 - 12:30) - Network Topology Inference</h4> <ul> <li>Polynomial graphical lasso and generalizations. A. G. Marques (Rey Juan Carlos University), A. Buciulea (Rey Juan Carlos University), J. Ying (The Hong Kong University of Science and Technology), and D.P. Palomar (The Hong Kong University of Science and Technology).</li> <li>Mitigating subpopulation bias for fair network topology inference. Madeline Navarro (Rice University), Samuel Rey (Rey Juan Carlos University), Andrei Buciulea Vlas (Universidad Rey Juan Carlos), Antonio G. Marques (Rey Juan Carlos University), Santiago Segarra (Rice University).</li> <li>Inferring the Topology of a Networked Dynamical Systems. Augusto A Santos (Instituto de Telecomunica es), Jos M. F. Moura (Carnegie Mellon University).</li> <li>Sampling and Consensus for Anomalous Edge Detection. Abdullah Karaaslanli (Michigan State University), Panagiotis Traganitis (Michigan State University), Selin Aviyente (Michigan State University).</li> <li>Introducing Graph Learning over Polytopic Uncertain Graph. Masako Kishida (National Institute of Informatics), Shunsuke Ono (Tokyo Institute of Technology).</li> <li>Laplacian-Constrained Cramer-Rao Bound for Networks Applications. Morad Halihal (Ben-Gurion University of the Negev), Tirza S Routtenberg (Ben Gurion University of the Negev).</li> </ul> <h4 id="oral-session-mon-pm-monday-1600---1740---graph-filters">Oral Session Mon-PM (Monday 16:00 - 17:40) - Graph filters</h4> <ul> <li>Involution-Based Graph-Signal Processing. Gerald Matz (Technische Universit t Wien), Dimitrios Kalodikis (TU Wien).</li> <li>On the Stability of Graph Spectral Filters: A Probabilistic Perspective. Ning Zhang (University of Oxford), Henry Kenlay (University of Oxford), Mihai Cucuringu (University of Oxford and The Alan Turing Institute), Xiaowen Dong (University of Oxford).</li> <li>Algebraic spaces of filters for signals on graphons. Alejandro Parada-Mayorga (University of Pennsylvania), Leopoldo Agorio (University of Pittsburgh), Alejandro Ribeiro (University of Pennsylvania), Juan Andres Bazerque (Univerity of Pittsburgh).</li> <li>Graph Filtering for Clustering Attributed Graphs. Meiby Ortiz-Bouza (Michigan State University), Selin Aviyente (Michigan State University).</li> <li>HoloNets: Spectral Convolutions do extend to Directed Graphs. Christian Koke (Technical University Munich), Daniel Cremers (TU Munich).</li> </ul> <h4 id="oral-session-tue-am-tuesday-1030---1230---signal-processing-on-higher-order-networks">Oral Session Tue-AM (Tuesday 10:30 - 12:30) - Signal processing on higher-order networks</h4> <ul> <li>Disentangling the Spectral Properties of the Hodge Laplacian: Not All Small Eigenvalues Are Equal. Vincent P. Grande (RWTH Aachen University), Michael Schaub (RWTH Aachen University).</li> <li>Simplicial Vector Autoregressive Models. Joshin P. Krishnan (Simula Metropolitan Center for Digital Engineering), Rohan Thekkemarickal Money (Simula), Baltasar Beferull-Lozano (Simula Metropolitan Center for Digital Engineering), Elvin Isufi (Tu Delft).</li> <li>Learning Graphs and Simplicial Complexes from Data. Andrei Buciulea Vlas (Rey Juan Carlos University), Elvin Isufi (Tu Delft), Geert Leus (TU Delft), Antonio G. Marques (Rey Juan Carlos University).</li> <li>Topological Dictionary Learning. Claudio Battiloro (Sapienza University of Rome), Paolo Di Lorenzo (Sapienza University of Rome), Alejandro Ribeiro (University of Pennsylvania).</li> <li>Hyperedge Representations with Deep Hypergraph Wavelets: Applications to Spatial Transcriptomics. Xingzhi Sun (Yale University), Charles Xu (Yale University), Benjamin Hollander-Bodie (Yale University), Laney Goldman (Harvey Mudd College), Michael Perlmutter (University of California, Los Angeles), Marcello DiStasio (Yale University), Smita Krishnaswamy (Yale University).</li> <li>Graph Neural Networks for predicting Chemical Toxicity, Akhil Gopinath (MathWorks).</li> </ul> <h4 id="oral-session-tue-pm-tuesday-1600---1720---graph-learning">Oral Session Tue-PM (Tuesday 16:00 - 17:20) - Graph learning</h4> <ul> <li>Graph Topology Learning with Functional Priors. Chenyue Zhang (The Chinese University of Hong Kong), Hoi-To Wai (Chinese University of Hong Kong), Shangyuan LIU (The Chinese University of Hong Kong).</li> <li>Enhanced Graph-Learning Schemes Driven by Similar Distributions of Motifs. Samuel Rey (Rey Juan Carlos University), T. Mitchell Roddenberry (Rice University), Santiago Segarra (Rice University), Antonio G. Marques (Rey Juan Carlos University).</li> <li>Heterogeneous Graph Structure Learning: A Statistical Perspective. Keyue Jiang (University College London), Bohan Tang (University of Oxford), Laura Toni (UCL), Xiaowen Dong (University of Oxford).</li> <li>Graph Structure Learning with Interpretable Bayesian Neural Networks. Max Wasserman (University of Rochester), Gonzalo Mateos (University of Rochester).</li> </ul> <h4 id="oral-session-wed-am-wednesday-1030---1230---geometric-deep-learning">Oral Session Wed-AM (Wednesday 10:30 - 12:30) - Geometric deep learning</h4> <ul> <li>Online Time Covariance Neural Networks. Andrea Cavallo (Delft University of Technology), Mohammad Sabbaqi (Delft University of Technology), Elvin Isufi (Tu Delft).</li> <li>From Latent Graph to Latent Topology Inference: Differentiable Cell Complex Module. Claudio Battiloro (Sapienza University of Rome), Indro Spinelli (Sapienza University of Rome), Lev Telyatnikov (Sapienza University), Michael Bronstein (Oxford University), Simone Scardapane (Sapienza University), Paolo Di Lorenzo (Sapienza University of Rome).</li> <li>Graph Convolutional Neural Networks in the Companion Model. John Shi (Carnegie Mellon University), Shreyas Chaudhari (Carnegie Mellon University), Jos M. F. Moura (Carnegie Mellon University).</li> <li>Representing Edge Flows on Graphs via Sparse Cell Complexes. Josef Hoppe (RWTH Aachen University), Michael Schaub (RWTH Aachen University).</li> <li>Multi-Scale Hydraulic Graph Neural Networks. Roberto Bentivoglio (TU Delft), Elvin Isufi (Tu Delft), Sebastiaan Nicolas Jonkman (TU Delft), Riccardo Taormina (TU Delft).</li> <li>Simplicial Scattering Networks. Hiren Madhu (Indian Institute of Science, Bengaluru), Sravanthi Gurugubelli (Indian Institute of Science), Sundeep Prabhakar Chepuri (Indian Institute of Science).</li> </ul> <h4 id="oral-session-wed-pm-wednesday-1600---1740---gsp-theory-and-methods">Oral Session Wed-PM (Wednesday 16:00 - 17:40) - GSP Theory and Methods</h4> <ul> <li>Quantile-based fitting for graph signals. Kyusoon Kim (Seoul National University).</li> <li>Mobius Total Variation for Directed Acyclic Graph. Vedran Mihal (ETH Zurich), Markus P schel (ETH Zurich).</li> <li>Median Autoregressive Graph Filters. David Tay (Deakin University).</li> <li>Blind Deconvolution of Sparse Graph Signals in the Presence of Perturbations. Victor M. Tenorio (Rey Juan Carlos University), Samuel Rey (Rey Juan Carlos University), Antonio G. Marques (Rey Juan Carlos University).</li> <li>Discrete Integral Operators for Graph Signal Processing. Naoki Saito (University of California, Davis), Eugene Shvarts (University of California, Davis).</li> </ul> <hr> <h4 id="poster-sessions">Poster Sessions</h4> <h4 id="poster-session-mon-monday-1300-14h00--15h00-16h00---euler">Poster Session Mon (Monday 13:00-14h00 &amp; 15h00-16h00) - Euler</h4> <ul> <li>Decentralized and Lifelong-Adaptive Multi-Agent Collaborative Learning. Shuo Tang (Stanford University), Rui Ye (Shanghai Jiao Tong University), Chenxin Xu (Shanghai Jiao Tong University), Xiaowen Dong (University of Oxford), Siheng Chen (Shanghai Jiao Tong University, Shanghai AI Laboratory), Yan-Feng Wang (Cooperative medianet innovation center of Shanghai Jiao Tong University).</li> <li>Online Graph Learning Via Proximal Newton Method from Streaming Data. Zu-Yu Wu (National Yang Ming Chiao Tung University), Carrson C. Fung (Carnegie Mellon University), Jun-Yi Chang (National Yang Ming Chiao Tung University), Hsin Chuang (National Yang Ming Chiao Tung University), Yi-Chen Lin (National Yang Ming Chiao Tung University).</li> <li>Online Graph Filtering Over Expanding Graphs. Bishwadeep Das (TU Delft), Elvin Isufi (Tu Delft)</li> <li>Hodge-Aware Matched Subspace Detectors. Chengen Liu (Tu Delft), Elvin Isufi (Tu Delft).</li> <li>Windowed Hypergraph Fourier Transform and Vertex-frequency Representation. Alcebiades Dal Col (Federal University of Espirito Santo), Fabiano Petronetto (Federal University of Espirito Santo), Juliano B. Lima (Federal University of Pernambuco), Jos R de Oliveira Neto (Universidade Federal de Pernambuco).</li> <li>Graph Signal Processing: The 2D Companion Model. John Shi (University of Michigan), Jos M. F. Moura (Carnegie Mellon University).</li> <li>Robust Graph Learning for Classification. Jingxin Zhang (Swinburne University of Technology), Subbareddy BATREDDY (IIT HYDERABAD), Aditya Siripuram (IIT Hyderabad).</li> <li>Sparse Recovery of Diffused Graph Signals. Gal Morgenstern (Ben-Gurion University of the Negev), Tirza S. Routtenberg (Ben-Gurion University of the Negev).</li> <li>Learning Stochastic Graph Neural Networks with Constrained Variance. Zhan Gao (University of Cambridge), Elvin Isufi (Tu Delft).</li> <li>On the Impact of Sample Size in Reconstructing Signals with Graph Laplacian Regularisation. Baskaran Sripathmanathan (University of Oxford), Xiaowen Dong (University of Oxford), Michael Bronstein (University of Oxford).</li> <li>Hypergraph Transformer for Semi-Supervised Classification. Zexi Liu (Shanghai Jiao Tong University), Bohan Tang (University of Oxford), Ziyuan Ye (The Hong Kong Polytechnic University), Xiaowen Dong (University of Oxford), Yanfeng Wang (Shanghai Jiao Tong University), Siheng Chen (Shanghai Jiao Tong University, Shanghai AI Laboratory).</li> <li>Convolutional GNN to process signals defined over DAGs. Samuel Rey (Rey Juan Carlos University), Hamed Ajorlou (University of Rochester), Gonzalo Mateos (University of Rochester).</li> <li>Graph Neural Networks with Adaptive Structure. Zepeng Zhang (EPFL), Songtao Lu (IBM Thomas J. Watson Research Center), Zengfeng Huang (Fudan University), Ziping Zhao (ShanghaiTech University).</li> <li>Efficient Task Planning with Taxonomy Graph States and Large Language Models. Rodrigo P rez Dattari (TU Delft), Zhaoting Li (TU Delft), Robert Babuska (TU Delft), Jens Kober (TU Delft), Cosimo Della Santina (TU Delft).</li> <li>Sampling sparse graph signals. Stefan Kunis (University of Osnabrueck).</li> <li>Learned Finite-Time Consensus for Distributed Optimization. Aaron Fainman (Imperial College London), Stefan Vlaski (Imperial College London).</li> </ul> <h4 id="poster-session-tue-tuesday-1300-14h00--15h00-16h00---laplace">Poster Session Tue (Tuesday 13:00-14h00 &amp; 15h00-16h00) - Laplace</h4> <ul> <li>ResolvNet: A Graph Convolutional Network with multi-scale Consistency. Christian Koke (TU Munich), Abhishek Saroha (TU Munich), Yuesong Shen (TU Munich), Marvin Eisenberger (TU Munich), Daniel Cremers (TU Munich).</li> <li>Multiscale Graph Signal Clustering. Reina Kaneko (Tohoku University), Kenta Yanagiya (Osaka University), Junya Hara (Osaka University), Hiroshi Higashi (Osaka University), Yuichi Tanaka (Osaka University).</li> <li>On Stability of GCNN Under Graph Perturbations. Jun Zhang (ShanghaiTech University), Ziping Zhao (ShanghaiTech University).</li> <li>Kernel graph filtering – a new method for dynamic sinogram denoising. Jingxin Zhang (Swinburne University of Technology), Shiyao Guo (GuiZhou University of Finance and Economics).</li> <li>Data-Aware Dynamic Network Decomposition. Bishwadeep Das (TU Delft), Andrei Buciulea Vlas (Rey Juan Carlos University), Antonio G. Marques (Rey Juan Carlos University), Elvin Isufi (Tu Delft).</li> <li>Hodge-Compositional Edge Gaussian Processes. Maosheng Yang (TU Delft), Viacheslav Borovitskiy (ETH Z rich), Elvin Isufi (Tu Delft).</li> <li>Estimators for Connection-Laplacian-Based Linear Algebra. Hugo Jaquard (GIPSA-lab), Nicolas Tremblay (CNRS), Simon Barthelm (CNRS), Pierre-Olivier Amblard (CNRS).</li> <li>Recovering Missing Node Features with Local Structure-based Embeddings. Victor M. Tenorio (Rey Juan Carlos University), Madeline Navarro (Rice University), Santiago Segarra (Rice University) Antonio G. Marques (Rey Juan Carlos University).</li> <li>Seeking universal approximation for continuous counterparts of GNNs on large random graphs. Matthieu Cordonnier (GIPSA-lab), Nicolas Tremblay (CNRS, GIPSA-lab), Nicolas Keriven (CNRS, GIPSA-lab), Samuel Vaiter (CNRS, Lab. J.A Dieudonn ).</li> <li>Benchmarking Graph Neural Networks with the Quadratic Assignment Problem. Adrien Lagesse (INRIA, ENS Paris), Marc Lelarge (INRIA-ENS).</li> <li>Inferring Time-Varying Signal over Uncertain Graphs. Mohammad Sabbaqi (TU Delft).</li> <li>Optimal Quasi-clique: Hardness Equivalence with Densest-k-Subgraph, and Quasi-partitioned Community Mining. Aritra Konar (KU Leuven), Nicholas D. Sidiropoulos (University of Virginia).</li> <li>Learning Causal Influences from Social Interactions. Mert Kayaalp (EPFL), Ali H. Sayed (EPFL).</li> <li>Peer-to-Peer Learning + Consensus with Non-IID Data. Srinivasa Pranav (Carnegie Mellon University), Jos M. F. Moura (Carnegie Mellon University</li> <li>Community mining by modeling multilayer networks with Cartesian product graphs. Tiziana Cattai (Sapienza University of Rome), Stefania Colonnese (Sapienza University of Rome, Italy).</li> <li>A Rewiring Contrastive Patch PerformerMixer Framework for Graph Representation Learning. Zhongtian Sun (Durham University), Anoushka Harit (Durham University), Alexandra Cristea (Durham University), Jingyun Wang (Durham university), Pietro Li (University of Cambridge), Jongmin Yu (University of Cambridge).</li> <li>Blind identification of overlapping communities from nodal observations. Ruben Wijnands (TU Delft), Geert Leus (TU Delft), Borbala Hunyadi (TUDelft).</li> <li>GSP-Traffic Dataset: Graph Signal Processing Dataset Based on Traffic Simulation. Rui Kumagai (Osaka University), Hayate KOJIMA (Tokyo University of Agriculture and Technology), Hiroshi Higashi (Osaka University), Yuichi Tanaka (Osaka University).</li> <li>A Novel Smoothness Prior for Hypergraph Machine Learning. Bohan Tang (University of Oxford), Siheng Chen (Shanghai Jiao Tong University, Shanghai AI Laboratory), Xiaowen Dong (University of Oxford).</li> </ul> <h4 id="poster-session-3-wednesday-1300-14h00--15h00-16h00---erdos">Poster Session 3 (Wednesday 13:00-14h00 &amp; 15h00-16h00) - Erdos</h4> <ul> <li>Utilizing graph Fourier transform for automatic Alzheimer s disease detection from EEG signals. Ramnivas Sharma (MNIT Jaipur), Hemant Kumar Meena (MNIT Jaipur).</li> <li>Emergence of Higher-Order Functional Brain Connectivity with Hypergraph Signal Processing. Breno C. Bispo (University of Amsterdam), Fernando Santos (University of Amsterdam), Jos R de Oliveira Neto (Universidade Federal de Pernambuco), Juliano B Lima (Federal University of Pernambuco).</li> <li>Protection Against Graph-Based False Data Injection Attacks on Power Systems. Gal Morgenstern (Ben-Gurion University of the Negev), Tirza S Routtenberg (Ben Gurion University of the Negev), Gil Zussman (Columbia University), James Anderson (Columbia University), Jip Kim (Korea Institute of Energy Technology).</li> <li>Arbitrarily Sampled Signal Reconstruction Using Relative Difference Features. Chin-Yun Yu (Queen Mary University of London), Johan Pauwels (Queen Mary University of London), George Fazekas (QMUL).</li> <li>Incorporating the spiral of silence into opinion dynamics. Shir Mamia (Bar Ilan University).</li> <li>scPrisma infers, filters and enhances topological signals in single-cell data using spectral template matching. Jonathan Karin (The Hebrew University), Yonathan Bornfeld (The Hebrew University), Mor Nitzan (The Hebrew University).</li> <li>Graph Neural Network-Based Node Deployment for Throughput Enhancement. Yifei Yang (Wuhan University), Dongmian Zou (Duke Kunshan University), Xiaofan He (Wuhan University).</li> <li>Attack Graph Model for Cyber-Physical Power Systems Using Hybrid Deep Learning. Alfan Presekal (TU Delft).</li> <li>Interpretable Diagnosis of Schizophrenia Using Graph-Based Brain Network Information Bottleneck. Tianzheng Hu (Vrije University), Shujian Yu (VU Amsterdam).</li> <li>Exploiting Variational Inequalities for Generalized Change Detection on Graphs. Juan F. Florez (University of Delaware).</li> <li>Measuring Structure-Function Coupling Using Joint-modes of Multimodal Brain Networks. Sanjay Ghosh (Indian Institute of Technology Kharagpur), Ashish Raj (UCSF), Srikantan Nagarajan (UCSF).</li> <li>Autoregressive GNN for emulating Stormwater Drainage Flows. Alexander Garz n (TU Delft), Zoran Kapelan (TU Delft), Jeroen Langeveld (TU Delft / Partners4UrbanWater), Riccardo Taormina (TU Delft).</li> <li>Faster Convergence with Less Communication: Broadcast-Based Subgraph Sampling for Decentralized Learning over Wireless Networks. Daniel P rez Herrera (Link ping University), Zheng Chen (Link ping University), Erik G. Larsson (Nil).</li> <li>Data-driven Polytopic Output Synchronization from Noisy Data. Wenjie Liu (Beijing Institute of Technology), Yifei Li (Beijing Institute of Technology), Gang Wang (Beijing Institute of Technology).</li> <li>A Graph Signal Processing Framework based on Graph Learning and Graph Neural Networks for Mental Workload Classification from EEG signals. Maria a Sarkis (LS2N), Mira Rizkallah (Ecole Centrale Nantes), Sa d Moussaoui (LS2N - SIMS).</li> <li>State Estimation in Water Distribution Systems using Diffusion on the Edge Space. Bulat Kerimov (NTNU), Maosheng Yang (TU Delft), Riccardo Taormina (TU Delft), Franz Tscheikner-Gratl (NTNU).</li> <li>Neuro-GSTH: Quantitative analysis of spatiotemporal neural dynamics using geometric scattering and persistent homology. Dhananjay Bhaskar (Yale University), Jessica Moore (Duke University), Yanlei Zhang (Mila), Rahul Singh (Yale University), Valentina Greco (Yale University), Joy Hirsch (Yale University), Smita Krishnaswamy (Yale University).</li> <li>PET Image Representation and Reconstruction based on Graph Filter. Jingxin Zhang (Swinburne University of Technology), Shiyao Guo (GuiZhou University of Finance and Economics).</li> </ul> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> Graph Signal Processing Workshop 2025. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-829BHZJPBN"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-829BHZJPBN");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>